{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf408a9f",
   "metadata": {},
   "source": [
    "# Self Case Study 1 - Ashrae Great Energy Predictor-III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f709536",
   "metadata": {},
   "source": [
    "- Reference- https://www.kaggle.com/code/arjanso/reducing-dataframe-memory-size-by-65/notebook\n",
    "- Reference- https://www.kaggle.com/code/caesarlupum/ashrae-start-here-a-gentle-introduction/notebook\n",
    "- Reference- https://www.kaggle.com/code/gemartin/load-data-reduce-memory-usage/notebook\n",
    "- Reference- https://www.kaggle.com/code/abhigyandatta/eda-ashrae-energy-consumption\n",
    "- Reference- https://www.kaggle.com/code/sakurakh/energy-prediction-ii\n",
    "- Reference- https://www.kaggle.com/code/syoshinaga/ashrae-eda\n",
    "- Reference- https://www.kaggle.com/code/emphymachine/3-ashrae-energy-prediction-eda-pjt\n",
    "- Reference- https://www.kaggle.com/code/usefgadallah/energy-prediction-eda\n",
    "- Reference- https://www.kaggle.com/code/ts1789/ashrae-part-2-feature-engineering-and-selection\n",
    "- Reference- https://www.kaggle.com/code/ts1789/ashrae-part-1-eda\n",
    "- Reference- https://www.kaggle.com/code/moatazbellahahmed/machine-project-eda\n",
    "- Reference- https://www.kaggle.com/code/salmazakzouk/ashrae-project\n",
    "- Reference- https://www.kaggle.com/code/varunjain113/ashrae-starting-dataset-tabularpandas-object\n",
    "- Reference- https://www.kaggle.com/datadugong/locate-better-cities-by-weather-temp-fill-nans\n",
    "- Reference- https://www.kaggle.com/c/ashrae-energy-prediction/discussion/115698\n",
    "- Reference- https://www.kaggle.com/patrick0302/locate-cities-according-weather-temperature\n",
    "- Reference- https://www.kaggle.com/code/ashishpatel26/feature-importance-of-lightgbm/notebook\n",
    "- Reference- https://www.kaggle.com/code/jeeperscreepers/ashrae-gep-iii-feature-engineering-try-1\n",
    "- Reference- https://www.kaggle.com/code/remisharoon/ashrae-gep-iii-rms-nb/notebook\n",
    "- Reference- https://www.kaggle.com/general/175075\n",
    "- Reference- https://www.kaggle.com/code/ryches/simple-lgbm-solution/notebook\n",
    "- Reference- https://www.kaggle.com/competitions/ashrae-energy-prediction/discussion/122863\n",
    "- Reference- https://www.kaggle.com/c/ashrae-energy-prediction/discussion/124984\n",
    "- Reference- https://www.kaggle.com/code/rohanrao/ashrae-half-and-half/notebook\n",
    "- Reference- https://stackoverflow.com/questions/57534739/catboosterror-cat-features-must-be-integer-or-string-real-number-values-and-na\n",
    "- Reference- https://www.analyticsvidhya.com/blog/2017/08/catboost-automated-categorical-data/\n",
    "- Reference- https://www.analyticsvidhya.com/blog/2021/08/complete-guide-on-how-to-use-lightgbm-in-python/\n",
    "- Reference- https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html\n",
    "- Reference- https://machinelearningmastery.com/light-gradient-boosted-machine-lightgbm-ensemble/\n",
    "- Reference- https://www.statisticshowto.com/variance-inflation-factor/\n",
    "- Reference- https://towardsdatascience.com/targeting-multicollinearity-with-python-3bd3b4088d0b\n",
    "- Reference- https://www.programcreek.com/python/example/88794/lightgbm.LGBMRegressor\n",
    "- Reference- https://numpy.org/doc/stable/reference/generated/numpy.expm1.html\n",
    "- Reference- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "- Reference- https://www.geeksforgeeks.org/random-forest-regression-in-python/\n",
    "- Reference- https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "- Reference- https://www.geeksforgeeks.org/numpy-expm1-python/\n",
    "- Reference- https://www.mikulskibartosz.name/how-to-reduce-memory-usage-in-pandas/\n",
    "- Reference- https://stackoverflow.com/questions/57531388/how-can-i-reduce-the-memory-of-a-pandas-dataframe\n",
    "- Reference- https://numpy.org/doc/stable/reference/generated/numpy.log1p.html#numpy.log1p\n",
    "- Reference- https://seaborn.pydata.org/generated/seaborn.distplot.html\n",
    "- Reference- https://www.folkstalk.com/2022/10/hwo-to-separate-datetime-column-into-date-and-time-pandas-with-code-examples.html\n",
    "- Reference- https://www.w3resource.com/pandas/series/series-dt-dayofweek.php\n",
    "- Reference- https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.dayofweek.html\n",
    "- Reference- https://stackabuse.com/rotate-axis-labels-in-matplotlib/\n",
    "- Reference- https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\n",
    "- Reference- https://hatarilabs.com/ih-en/how-to-make-a-wind-rose-with-python-tutorial\n",
    "- Reference- https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
    "- Reference- https://www.geeksforgeeks.org/colormaps-in-seaborn-heatmaps/\n",
    "- Reference- https://medium.com/analytics-vidhya/ashrae-great-energy-predictor-iii-a-machine-learning-case-study-a01a67eb048d\n",
    "- Reference- https://www.researchgate.net/publication/343855462_The_ASHRAE_Great_Energy_Predictor_III_competition_Overview_and_results\n",
    "- Reference- https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month.html\n",
    "- Reference- https://stackoverflow.com/questions/30222533/create-a-day-of-week-column-in-a-pandas-dataframe-using-python\n",
    "- Reference- https://stackoverflow.com/questions/68035628/split-date-into-day-of-the-week-month-year-using-pyspark\n",
    "- Reference- https://towardsdatascience.com/violin-strip-swarm-and-raincloud-plots-in-python-as-better-sometimes-alternatives-to-a-boxplot-15019bdff8f8\n",
    "- Reference- https://medium.com/@chandanaroyal99/ashrae-great-energy-predictor-iii-case-study-66a25acd77f0\n",
    "- Reference- https://blog.insightdatascience.com/data-visualization-in-python-advanced-functionality-in-seaborn-20d217f1a9a6\n",
    "- Reference- https://opensource.com/article/20/4/plot-data-python\n",
    "- Reference- https://www.geeksforgeeks.org/matplotlib-pyplot-legend-in-python/\n",
    "- Reference- https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "- Reference- https://seaborn.pydata.org/generated/seaborn.color_palette.html#seaborn.color_palette\n",
    "- Reference- https://bmcnoldy.rsmas.miami.edu/Humidity.html\n",
    "- Reference- https://bmcnoldy.rsmas.miami.edu/humidity_conversions.pdf\n",
    "- Reference- https://pypi.org/project/meteocalc/\n",
    "- Reference- https://www.geeksforgeeks.org/python-holidays-library/\n",
    "- Reference- https://towardsdatascience.com/5-minute-guide-to-detecting-holidays-in-python-c270f8479387\n",
    "- Reference- https://scikit-learn.org/stable/modules/cross_validation.html#:~:text=in%20each%20repetition.-,Leave%20One%20Out%20(LOO),-%C2%B6\n",
    "- Reference- https://www.kaggle.com/code/remisharoon/ashrae-gep-iii-rms-nb/notebook\n",
    "- Reference- https://medium.com/@ayushv23/ashrae-great-energy-predictor-iii-a-machine-learning-case-study-5f36abfe54ad\n",
    "- Reference- https://lightgbm.readthedocs.io/en/latest/Python-Intro.html\n",
    "- Reference- https://stackoverflow.com/questions/53413701/feature-importance-using-lightgbm\n",
    "- Reference- https://www.askpython.com/python/examples/rmse-root-mean-square-error\n",
    "- Reference- https://stackoverflow.com/questions/17197492/is-there-a-library-function-for-root-mean-square-error-rmse-in-python\n",
    "- Reference- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\n",
    "- Reference- https://www.geeksforgeeks.org/ml-mathematical-explanation-of-rmse-and-r-squared-error/\n",
    "- Reference- https://medium.com/scavs-ai/feature-selection-with-lofo-importance-540b9d77b734\n",
    "- Reference- https://stackoverflow.com/questions/71692741/using-groupkfold-with-lofo-importance\n",
    "- Reference- https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
    "- Reference- http://statisticshowto.com/variance-inflation-factor/\n",
    "- Reference- https://www.geeksforgeeks.org/detecting-multicollinearity-with-vif-python/\n",
    "- Reference- https://pub.towardsai.net/ashrae-great-energy-prediction-challenge-cefab05e4f2\n",
    "- Reference- https://github.com/buds-lab/ashrae-great-energy-predictor-3-solution-analysis\n",
    "- Reference- https://github.com/vdhar1992/ASHRAE_Great_energy_predictorIII_CaseStudy/blob/main/ASHRAE_GreatEnergyPredictorIII.ipynb\n",
    "- Reference- https://github.com/manas3858/ASHRAE---Great-Energy-Predictor-III/blob/master/ASHRAE%20Challenge.ipynb\n",
    "- Reference- https://github.com/Apoorvajasti/ASHRAE-Great-Energy-Predictor-III/blob/master/Intro%20to%20Data%20-%20ASHRAE%20Project%20(Python%20-%20Colab).ipynb\n",
    "- Reference- https://github.com/energeeks/ashrae-energy-prediction\n",
    "- Reference- https://github.com/Taher-web-dev/ASHRAE---Great-Energy-Predictor-III/blob/master/Cleaning%20and%20data%20exploration%20_%20interesting%20.ipynb\n",
    "- Reference- https://github.com/VikasSingh-DS/kaggle-ASHRAE-Great-Energy-Comp/blob/master/ashrae-great-energy-insightful-eda-fe-lgbm.ipynb\n",
    "- Reference- https://github.com/manikayya/ASHRAE-Great-Energy-Prediction-III/blob/main/EDA_ASHRAE_Great_Energy_Predictor_III.ipynb\n",
    "- Reference- https://github.com/aerdem4/lofo-importance/blob/master/LOFOImportance%20Example.ipynb\n",
    "- Reference- https://etav.github.io/python/vif_factor_python.html\n",
    "- Reference- https://github.com/energeeks/ashrae-energy-prediction/tree/master/notebooks\n",
    "- Reference- https://github.com/Chandugundluru/Ashrae-Great-Energy-predictor\n",
    "- Reference- https://github.com/ayush-a11y/ASHRAE---Great-Energy-Predictor-III\n",
    "- Reference- https://github.com/vdhar1992/ASHRAE_Great_energy_predictorIII_CaseStudy/blob/main/Model_deployement.ipynb\n",
    "- Reference- https://github.com/martian1231/caseStudyOne/tree/main/streamlitApp\n",
    "- Reference- https://github.com/martian1231/caseStudyOne/blob/main/ASHRAE_Great_Energy_Predictor_III(Modeling).ipynb\n",
    "- Reference- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "- Reference- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "- Reference- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "- Reference- https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html\n",
    "- Reference- https://catboost.ai/en/docs/concepts/python-reference_catboostregressor\n",
    "- Reference- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html\n",
    "- Reference- https://www.analyticsvidhya.com/blog/2020/12/improve-predictive-model-score-stacking-regressor/\n",
    "- Reference- https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/\n",
    "- Reference- https://towardsdatascience.com/just-keep-stacking-implement-stacking-regression-in-python-using-mlxtend-3250ff327ee5\n",
    "- Reference- https://machinelearningmastery.com/xgboost-for-regression/\n",
    "- Reference- https://stackoverflow.com/questions/11285613/selecting-multiple-columns-in-a-pandas-dataframe\n",
    "- Reference- https://stackoverflow.com/questions/43855162/rmse-rmsle-loss-function-in-keras\n",
    "- Reference- https://www.samy101.com/projects/2019-kaggle-ashraegep3/\n",
    "- Reference- https://martian1231-py.medium.com/ashrae-great-energy-predictor-iii-a-machine-learning-self-case-study-5c9e9d0ea11d\n",
    "- Reference- https://www.analyticsvidhya.com/blog/2019/12/6-powerful-feature-engineering-techniques-time-series/\n",
    "- Reference- https://stackoverflow.com/questions/12555323/how-to-add-a-new-column-to-an-existing-dataframe\n",
    "- Reference- https://towardsdatascience.com/estimating-counterfactual-energy-usage-of-buildings-with-machine-learning-8ca91ec66c08\n",
    "- Reference- https://stackoverflow.com/questions/32565829/simple-way-to-measure-cell-execution-time-in-ipython-notebook\n",
    "- Reference- https://gsarantitis.wordpress.com/2019/07/16/how-to-persist-categorical-encoding-in-machine-learning-deployment-phase/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf152756",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from meteocalc import feels_like, Temp\n",
    "import datetime as dt\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "import holidays\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5661517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.52 ms, sys: 47 µs, total: 4.57 ms\n",
      "Wall time: 4.26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query_1 = pd.read_csv('query_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08142e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_function_1(model_file,data):\n",
    "    \n",
    "    data['meter'].replace({0:'electricity',1:'chilledwater',2:'steam',3:'hotwater'},inplace=True)\n",
    "    # replacing meter feature values with their names\n",
    "    \n",
    "    data['square_feet'] = np.log1p(data['square_feet']) # log convert square_feet feature\n",
    "    \n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp']) # adding time related features\n",
    "    data['hour'] = np.uint8(data['timestamp'].dt.hour)\n",
    "    data['day_of_week'] = np.uint8(data['timestamp'].dt.dayofweek)\n",
    "    data['month'] = np.uint8(data['timestamp'].dt.month)\n",
    "    data['day_of_year'] = np.uint16(data['timestamp'].dt.dayofyear)  \n",
    "    data['day'] = np.uint16(data['timestamp'].dt.day)\n",
    "    data['year']= np.uint16(data['timestamp'].dt.year)\n",
    "    \n",
    "    air_temp = data.groupby(['day','site_id','month'])['air_temperature'].transform('mean')\n",
    "    data['air_temperature'].fillna(air_temp,inplace=True) # filling NA values in air_temperature feature\n",
    "    \n",
    "    cloud_cover = data.groupby(['day','site_id','month'])['cloud_coverage'].transform('mean')\n",
    "    data['cloud_coverage'].fillna(cloud_cover,inplace=True) # filling NA values in cloud_coverage feature\n",
    "    \n",
    "    dew_temp = data.groupby(['day','site_id','month'])['dew_temperature'].transform('mean')\n",
    "    data['dew_temperature'].fillna(dew_temp,inplace=True) # filling NA values in dew_temperature feature\n",
    "    \n",
    "    precip_depth = data.groupby(['day','site_id','month'])['precip_depth_1_hr'].transform('mean')\n",
    "    data['precip_depth_1_hr'].fillna(precip_depth,inplace=True) # filling NA values in precip_depth_1_hr feature\n",
    "    \n",
    "    sea_level = data.groupby(['day','site_id','month'])['sea_level_pressure'].transform('mean')\n",
    "    data['sea_level_pressure'].fillna(sea_level,inplace=True) # filling NA values in sea_level_pressure feature\n",
    "    \n",
    "    wind_dir = data.groupby(['day','site_id','month'])['wind_direction'].transform('mean')\n",
    "    data['wind_direction'].fillna(wind_dir,inplace=True) # filling NA values in wind_direction feature\n",
    "    \n",
    "    wind_speed = data.groupby(['day','site_id','month'])['wind_speed'].transform('mean')\n",
    "    data['wind_speed'].fillna(wind_speed,inplace=True) # filling NA values in wind_speed feature\n",
    "    \n",
    "    data['cloud_coverage'].fillna(data['cloud_coverage'].median(),inplace=True)\n",
    "    data['precip_depth_1_hr'].fillna(data['precip_depth_1_hr'].median(),inplace=True)\n",
    "    data['sea_level_pressure'].fillna(data['sea_level_pressure'].median(),inplace=True)\n",
    "    # filling NA values in above features using median values\n",
    "    \n",
    "    data['relative_humidity'] = 100*(np.exp((17.625*data['dew_temperature'])/(243.04+data['dew_temperature']))/(np.exp((17.625*data['air_temperature'])/(243.04+data['air_temperature']))))\n",
    "    # adding relative_humidity feature to data\n",
    "    \n",
    "    air_temp = list(data['air_temperature'])\n",
    "    rel_humid = list(data['relative_humidity'])\n",
    "    winds_speed = list(data['wind_speed'])\n",
    "\n",
    "    feelike_final = []\n",
    "    feelike = []\n",
    "    for i in range(len(data)):   \n",
    "        feelike.append(feels_like(Temp(air_temp[i], unit = 'C'), rel_humid[i], winds_speed[i]))\n",
    "\n",
    "    for i in range(len(feelike)):\n",
    "        feelike_final.append(feelike[i].f)\n",
    "    data['feels_like'] = feelike_final # adding feels_like feature to data\n",
    "    \n",
    "    areas = pd.DataFrame()\n",
    "    areas['site_id'] = np.arange(0,16)\n",
    "    areas['city'] = ['Orlando','Heathrow','Tempe','Washington','Berkeley','Southampton','Washington','Ottowa',\n",
    "                     'Orlando','Austin','Saltlake','Ottowa','Dublin','Minneapolis','Philadelphia','Rochester']\n",
    "    areas['country'] = ['US','UK','US','US','US','UK','US','Canada','US','US','US','Canada','Ireland','US',\n",
    "                        'US','US']\n",
    "    \n",
    "    data = data.merge(areas,on='site_id',how='left') # adding areas feature to data\n",
    "    \n",
    "    USA=[]\n",
    "    for ptr in holidays.UnitedStates(years=2016).keys(): #2016-2018 year all holidays in USA\n",
    "        USA.append(str(ptr))\n",
    "    for ptr in holidays.UnitedStates(years=2017).keys():\n",
    "        USA.append(str(ptr))\n",
    "    for ptr in holidays.UnitedStates(years=2018).keys():\n",
    "        USA.append(str(ptr))\n",
    "        USA.append('2019-01-01')\n",
    "\n",
    "    United_Kingdom=[]\n",
    "    for ptr in holidays.UnitedKingdom(years=2016).keys():\n",
    "        United_Kingdom.append(str(ptr))\n",
    "    for ptr in holidays.UnitedKingdom(years=2017).keys(): #2016-2018 year all holidays in United_Kingdom\n",
    "        United_Kingdom.append(str(ptr))\n",
    "    for ptr in holidays.UnitedKingdom(years=2018).keys():\n",
    "        United_Kingdom.append(str(ptr))\n",
    "        United_Kingdom.append('2019-01-01')\n",
    "\n",
    "    Canada=[]\n",
    "    for ptr in holidays.Canada(years=2016).keys():   #2016-2018 year all holidays in Canada\n",
    "        Canada.append(str(ptr))\n",
    "    for ptr in holidays.Canada(years=2017).keys():\n",
    "        Canada.append(str(ptr))\n",
    "    for ptr in holidays.Canada(years=2018).keys():\n",
    "        Canada.append(str(ptr))\n",
    "        Canada.append('2019-01-01')\n",
    "\n",
    "    Ire_land=[]\n",
    "    for ptr in holidays.Ireland(years=2016).keys():  #2016-2018 year all holidays in Ireland\n",
    "        Ire_land.append(str(ptr))\n",
    "    for ptr in holidays.Ireland(years=2017).keys():\n",
    "        Ire_land.append(str(ptr))\n",
    "    for ptr in holidays.Ireland(years=2018).keys():\n",
    "        Ire_land.append(str(ptr))\n",
    "        Ire_land.append('2019-01-01')\n",
    "\n",
    "    data['holiday']=[0]*(data.shape[0])\n",
    "\n",
    "    data.loc[data['country']=='US','holiday']=(data['timestamp'].dt.date.astype('str').isin(USA)).astype(int)\n",
    "    data.loc[data['country']=='UK','holiday']=(data['timestamp'].dt.date.astype('str').isin(United_Kingdom)).astype(int)\n",
    "    data.loc[data['country']=='Canada','holiday']=(data['timestamp'].dt.date.astype('str').isin(Canada)).astype(int)\n",
    "    data.loc[data['country']=='Ireland','holiday']=(data['timestamp'].dt.date.astype('str').isin(Ire_land)).astype(int)\n",
    "    # adding holiday feature to data\n",
    "    \n",
    "    data['season'] = data['month'].apply(lambda i: 'Spring' if i==3 or i==4 or i==5 else 'Summer' if \n",
    "                                         i==6 or i==7 or i==8 \n",
    "                                         else 'Autumn' if i==9 or i==10 or i==11 else 'Winter')\n",
    "    # adding season feature to data\n",
    "\n",
    "    data['Day_Time']= data['hour'].apply(lambda i: 1 if i >=6 and i <=18 else 0)\n",
    "    # adding Day_Time feature to data\n",
    "    \n",
    "    latitude_dict = {0 :28.5383,1 :50.9097,2 :33.4255,3 :38.9072,4 :37.8715,5 :50.9097,6 :40.7128,7 :45.4215,\n",
    "                     8 :28.5383,9 :30.2672,10 :40.10677,11 :45.4215,12 :53.3498,13 :44.9375,14 :38.0293,\n",
    "                     15: 40.7128}\n",
    "\n",
    "    data['Latitude'] = data['site_id'].map(latitude_dict)\n",
    "    data['Solar_Hour'] = (data['hour']-12)*15\n",
    "    data['Solar_Dec'] = -23.45*np.cos(np.deg2rad(360*(data['day']+10)/365))\n",
    "    data['Horiz_Solar'] = np.cos(np.deg2rad(data['Solar_Hour']))*np.cos(np.deg2rad(data['Solar_Dec']))*np.cos(np.deg2rad(data['Latitude'])) + np.sin(np.deg2rad(data['Solar_Dec']))*np.sin(np.deg2rad(data['Latitude']))\n",
    "    data['Horiz_Solar'] = data['Horiz_Solar'].apply(lambda x: 0 if x <0 else x)\n",
    "    # adding Latitude, Solar_Hour, Solar_Dec, and Horiz_Solar feature to data\n",
    "    \n",
    "    data['Air_Temp_Diff'] = data['air_temperature'] - data.groupby(['building_id', 'meter'])['air_temperature'].shift(1)\n",
    "    data['Air_Temp_Diff'].fillna(data['Air_Temp_Diff'].median(),inplace=True)\n",
    "    # adding Air_Temp_Diff feature to data\n",
    "    \n",
    "    file_1 = open('label_encode_1.obj','rb')\n",
    "    label_1 = pickle.load(file_1)\n",
    "    file_1.close()\n",
    "    data['primary_use'] = label_1.transform(data['primary_use'])\n",
    "\n",
    "    file_2 = open('label_encode_2.obj','rb')\n",
    "    label_2 = pickle.load(file_2)\n",
    "    file_2.close()\n",
    "    data['season'] = label_2.transform(data['season'])\n",
    "\n",
    "    file_3 = open('label_encode_3.obj','rb')\n",
    "    label_3 = pickle.load(file_3)\n",
    "    file_3.close()\n",
    "    data['meter'] = label_3.transform(data['meter'])\n",
    "    # label encoding features- 'primary_use', 'season', and 'meter'\n",
    "    \n",
    "    data.drop(['city','country','row_id','timestamp','year_built','floor_count'],axis=1,inplace=True)\n",
    "    # dropping unnecessary features\n",
    "    \n",
    "    model = joblib.load(model_file)\n",
    "    prediction = model.predict(data) # predicting using the best model\n",
    "    prediction = np.expm1(prediction)\n",
    "    print('predicted meter-reading- ',prediction)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d3b9ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted meter-reading-  [74.41488996]\n",
      "CPU times: user 257 ms, sys: 22.4 ms, total: 280 ms\n",
      "Wall time: 66.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_function_1('LGBM_GBDT_reg_model.sav',query_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4f8e03",
   "metadata": {},
   "source": [
    "##### We need to label_encode test_data features- 'meter', 'primary_use' and 'season'.\n",
    "##### So, I've created an object of all the three labels and stored them in a pickle file, and  used these objects for label encoding the above said features.\n",
    "##### As directed, I've taken up one query point (1xd feature) and made prediction using the model.\n",
    "##### All operations, as directed, are in one single function- final_function_1. \n",
    "##### The whole model prediction run up for a single query point takes upto just 1 second on this machine.\n",
    "#### Query- In directions(from abstract file), for writing the final_function_2, we are asked to give error value between y_true and y_predicted. Kindly provide y_true for writing final_function_2.\n",
    "### Here is my deployment video of the case study. I've used StreamLit and NGROK apps for deploying the model.\n",
    "### Deployment Video- https://drive.google.com/file/d/1jb2XfN0xdb8U5YUhfpmonDiTK4DBWDFr/view?usp=share_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdd0ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
